{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **载入包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from collections import Counter\n",
    "import random\n",
    "import jieba\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence,pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **设置随机种子**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f4d96b1e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **设定超参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "MAX_VOCAB_SIZE = 30000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "EMB_DIM = 256\n",
    "HIDDEN_SIZE = 512\n",
    "DROPOUT = 0.5\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **加载数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(in_file):\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    with open(in_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            context, target = line.strip().split('\\t') #context 和target是string\n",
    "            context_list = context.split()\n",
    "            target_list = list(jieba.cut(target, cut_all=False, HMM=True))\n",
    "            contexts.append([\"<bos>\"] + context_list + [\"<eos>\"])\n",
    "            targets.append([\"<bos>\"] + target_list + [\"<eos>\"])\n",
    "    return contexts,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1.DES\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.768 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:/Users/Administrator.DESKTOP-10M2D22/Desktop/nlp-beginner/cmn.txt\"\n",
    "contexts,targets= load_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **构建单词表**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_voc(sentences, max_words=MAX_VOCAB_SIZE):\n",
    "    word_count = Counter()\n",
    "    for sentence in sentences:\n",
    "        for s in sentence:\n",
    "            word_count[s] += 1\n",
    "    vocab_dict = dict(word_count.most_common(max_words))\n",
    "    #most_common(n) 按照counter的计数，按照降序，返回前max_words项组成的list，比总单词数大时返回全部项。\n",
    "    total_wds = len(vocab_dict)+2                #加上<unk>和<pad>\n",
    "    id2wd = [w for w in vocab_dict.keys()]       #单词构成的list\n",
    "    wd2id = {}\n",
    "    for i,w in enumerate(id2wd):\n",
    "        wd2id[w] = i + 2                              #单词:id +2 构成的dict\n",
    "    wd2id[\"<unk>\"] = UNK_IDX\n",
    "    wd2id[\"<pad>\"] = PAD_IDX\n",
    "    id2wd = id2wd+[\"<unk>\",\"<pad>\"]\n",
    "    return id2wd,wd2id,total_wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2en,en2id,total_en = build_voc(contexts)\n",
    "id2cn,cn2id,total_cn = build_voc(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, contexts, targets, en2id, cn2id, sort_by_len=True):\n",
    "        super().__init__()\n",
    "        self.en2id = en2id\n",
    "        self.cn2id = cn2id\n",
    "        self.sort_by_len = sort_by_len\n",
    "\n",
    "        self.contexts = [torch.LongTensor([en2id.get(w, 0) for w in sent]) for sent in contexts]\n",
    "        self.targets = [torch.LongTensor([cn2id.get(w, 0) for w in sent]) for sent in targets]\n",
    "\n",
    "        if self.sort_by_len:\n",
    "            self.sorted_idx = sorted(range(len(self.contexts)), key=lambda x: len(self.contexts[x]))\n",
    "            self.contexts = [self.contexts[i] for i in self.sorted_idx]\n",
    "            self.targets = [self.targets[i] for i in self.sorted_idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.contexts)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        context = self.contexts[idx]\n",
    "        target = self.targets[idx]\n",
    "        context_len = torch.numel(self.contexts[idx])\n",
    "        target_len = torch.numel(self.targets[idx])\n",
    "        return {'context': context, 'target': target, 'context_len': context_len, 'target_len': target_len}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(batch):\n",
    "    #the input（batch）to collate_fn is a list of with size batch_size.Each element is a dict where elements in order are context,target,context_len,target_len.\n",
    "    res_batch = {}\n",
    "    for key in batch[0]:\n",
    "        batch_tensor = [d[key] for d in batch]\n",
    "        if key == \"context\" or key ==\"target\":\n",
    "            batch_tensor = pad_sequence(batch_tensor,batch_first=True)\n",
    "        res_batch[key] = batch_tensor\n",
    "    return res_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = MyDataset(contexts,targets,en2id,cn2id)\n",
    "train_size = int(0.6 * len(full_dataset))\n",
    "valid_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - valid_size\n",
    "train_dataset,valid_dataset,test_dataset = torch.utils.data.random_split(full_dataset, [train_size,valid_size,test_size])\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=my_collate_fn)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=my_collate_fn)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=my_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_emb, emb_dim, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        self.num_emb = num_emb\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(num_emb, emb_dim) #词表大小，嵌入维度\n",
    "        self.rnn = nn.GRU(emb_dim,hidden_size,batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x,x_lengths):\n",
    "        # x = [batch_size,batch_len]\n",
    "        # print(x.size())\n",
    "        # x_lengths is a list of context_len\n",
    "        embedded = self.dropout(self.embedding(x)) # LongTensor of arbitrary shape containing the indices to extract\n",
    "        # embdded = [batch_size, batch_len,emb_dim]\n",
    "\n",
    "        packed_embedded = pack_padded_sequence(embedded,x_lengths,batch_first=True,enforce_sorted=False)\n",
    "        # input(Tensor):padded batch of variable length sequences.lengths(list):list of sequences lengths of each batch element.\n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "        # hidden = [num_layers * num_directions,batch_size,hidden_size]\n",
    "        hidden = hidden.permute(1,0,2) #返回的是batch_size是在第二位，必须手动调整到第一位\n",
    "        # hidden = [batch_size,num_layers * num_directions,hidden_size]\n",
    "        outputs, _ = pad_packed_sequence(packed_outputs)\n",
    "        # outputs = [batch_len,batch_size,num_directions * hidden_size]\n",
    "        outputs = outputs.permute(1,0,2) #注意这里的batch是在第二位，必须手动调整到第一位\n",
    "        # outputs = [batch_size,batch_len,num_directions * hidden_size]\n",
    "        '''关于pack_padded_sequence和pad_packed_sequence函数，可以参考https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
    "        官方文档，以及两个函数的源码，写的比较清楚。'''\n",
    "        return outputs, hidden[:,-1,:] #我们只需要最后一个time step的最上层的hidden, [batch_size,hidden_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_size+hidden_size,hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "\n",
    "    def forward(self,hidden,encoder_outputs):\n",
    "        # encoder_outputs = [batch_size,batch_len, hidden_size] 这个outputs是encoder每一个time step的hiddens\n",
    "        # hidden = [batch_size,hidden_size] 这个hidden是从encoder最后一个time step的hidden，传递过来的，是作为decoder的hidden_0\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        batch_len = encoder_outputs.shape[1]\n",
    "        hidden = hidden.repeat(1,batch_len,1)\n",
    "        # hidden = [batch_size,batch_len,hidden_size]\n",
    "        tmp = torch.cat((hidden,encoder_outputs),dim = 2)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden,encoder_outputs),dim = 2)))\n",
    "        # energy = [batch_size,batch_len,hidden_size]\n",
    "        energy = energy.permute(0,2,1)\n",
    "        # energy = [batch_size,hidden_size,batch_len]\n",
    "        # self.v = [hidden_size]\n",
    "        v =self.v.repeat(batch_size,1).unsqueeze(1)\n",
    "        # v = [batch_size,1,hidden_size]\n",
    "        attention = torch.bmm(v,energy)\n",
    "        # attention = [batch_size,1,batch_len]\n",
    "        attention = attention.squeeze(1)\n",
    "        # attention = [batch_size,batch_len]\n",
    "        return F.softmax(attention,dim=1) # This gives us the attention over the source sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module): #decoder层包含了attention 层\n",
    "    def __init__(self, num_emb, emb_dim, hidden_size, dropout,attention):\n",
    "        super().__init__()\n",
    "        self.num_emb = num_emb\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(num_emb, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim + hidden_size, hidden_size, batch_first=True) #这个batch_first只能要求input的batch_size在第一位\n",
    "        self.out = nn.Linear(emb_dim + hidden_size + hidden_size, num_emb)\n",
    "\n",
    "    def forward(self,y_0,h_0,encoder_outputs): #h_0是encoder的最后一个time step的hidden，outputs是encoder每一个time step的hiddens\n",
    "        # y_0 = [batch_size]\n",
    "        # h_0 = [batchs_size,hidden_size]\n",
    "        # encoder_outputs = [batch_size,batch_len,hidden_size]\n",
    "        y_0 = y_0.unsqueeze(1)\n",
    "        h_0 = h_0.unsqueeze(1)\n",
    "        # y_0 = [batch_size,1]\n",
    "        # h_0 = [batch_size,1,hidden_size]\n",
    "\n",
    "        a = self.attention(h_0,encoder_outputs).unsqueeze(1)\n",
    "        # a = [batch_size,1,batch_len]\n",
    "        weighted = torch.bmm(a,encoder_outputs) # a weighted source vector\n",
    "        # weighted = [batch_size,1,hidden_size]\n",
    "        embedded = self.dropout(self.embedding(y_0))\n",
    "        # embdded = [batch_size,1,emb_dim]\n",
    "        rnn_input = torch.cat((embedded,weighted),dim = -1)\n",
    "        # rnn_input = [batch_size,1,emb_dim + hidden_size]\n",
    "        h_0 = h_0.permute(1,0,2)\n",
    "        # h_0 = [1,batchs_size,hidden_size]\n",
    "        output, hidden = self.rnn(rnn_input,h_0)\n",
    "        hidden = hidden.permute(1,0,2)\n",
    "        # hidden = [batch_size,1,hidden_size]\n",
    "        # output = [batch_size,1, hidden_size]\n",
    "        output = torch.cat((embedded.squeeze(1),hidden.squeeze(1),weighted.squeeze(1)),dim = 1)\n",
    "        # output = [batch_size.emb_dim+hidden_size+hidden_size]\n",
    "        prediction = self.out(output)\n",
    "        # prediction = [batch_size,num_emb]\n",
    "        return prediction, hidden[:,-1,:] #去除降维变成 hidden[:,-1,:] = [batch_size,hidden_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Seq2Seq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self,x,x_lengths,y):\n",
    "        # x = [batch_size,context_len]\n",
    "        # x_lengths is a list of context_len\n",
    "        # y = [batch_size,target_len]\n",
    "        encoder_outputs, hidden = self.encoder(x, x_lengths)  # 进行encoder\n",
    "\n",
    "        target_len = y.shape[-1]\n",
    "        batch_size = y.shape[0]\n",
    "        outputs = torch.zeros(batch_size,target_len,self.decoder.num_emb)\n",
    "        # outputs = [batch_size,target_len,num_emb]\n",
    "        y_0 = y[:,0]\n",
    "        # y_0 =[batch_size]\n",
    "        h_0 = hidden\n",
    "        # h_0 = [batch_size,hidden_size]\n",
    "        for t in range(1, target_len):\n",
    "            prediction, hidden = self.decoder(y_0,h_0,encoder_outputs) #decoder传入的参数h_0是来自encoder的hidden\n",
    "            # prediction = [batch_size,num_emb]\n",
    "            outputs[:,t,:] = prediction\n",
    "            y_0= y[:,t]\n",
    "        return outputs,None\n",
    "        # outputs = [batch_size,target_len,num_emb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **初始化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(num_emb = total_en, emb_dim = EMB_DIM, hidden_size = HIDDEN_SIZE, dropout = DROPOUT)\n",
    "attn = Attention(HIDDEN_SIZE)\n",
    "decoder = Decoder(num_emb = total_cn, emb_dim = EMB_DIM, hidden_size = HIDDEN_SIZE, dropout = DROPOUT,attention=attn)\n",
    "model = Seq2Seq(encoder,decoder)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **定义训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataloader,optimizer,criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        prediction, attn = model(batch[\"context\"],batch[\"context_len\"],batch[\"target\"])\n",
    "        # [batch_size,context_len],x_lengths is a list of context_len, [batch_size,target_len]\n",
    "        target = batch[\"target\"]\n",
    "        # target = [batch_size,target_len]\n",
    "        # prediction = [batch_size,target_len，num_emb]\n",
    "        target =target.contiguous()\n",
    "        target = target[:,1:].reshape(-1)\n",
    "        prediction = prediction[:,1:,:].reshape(-1,prediction.shape[-1])\n",
    "        # target = [batch_size*(target_len-1)]\n",
    "        # prediction = [batch_size*(target_len-1),num_emb] #不要第一个<bos>\n",
    "        loss = criterion(prediction, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **定义测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataloader,criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            prediction, attn = model(batch[\"context\"],batch[\"context_len\"],batch[\"target\"])\n",
    "            # [batch_size,context_len],x_lengths is a list of context_len, [batch_size,target_len]\n",
    "            target = batch[\"target\"]\n",
    "            # target = [batch_size,target_len]\n",
    "            # prediction = [batch_size,target_len，num_emb]\n",
    "            target =target.contiguous()\n",
    "            target = target[:,1:].reshape(-1)\n",
    "            prediction = prediction[:,1:,:].reshape(-1,prediction.shape[-1])\n",
    "            # target = [batch_size*(target_len-1)]\n",
    "            # prediction = [batch_size*(target_len-1),num_emb] #不要第一个<bos>\n",
    "            loss = criterion(prediction, target)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **每个epoch所用时间**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time,end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins*60))\n",
    "    return elapsed_mins,elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float(\"inf\")\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model,train_dataloader,optimizer,criterion)\n",
    "    valid_loss = evaluate(model, valid_dataloader,criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins,epoch_secs = epoch_time(start_time,end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(),\"./model.pt\")\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "test_loss = evaluate(model, test_dataloader, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
